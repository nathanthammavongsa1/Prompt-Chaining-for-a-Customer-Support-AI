{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7vZMJ2Wyt7i",
        "outputId": "0cb4b04b-5bcf-4f11-fbb8-74ad176ebcda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CHAIN STEP] Classification prompt:\n",
            " You are a customer support triage assistant.\n",
            "\n",
            "Task: Classify the user's issue and list any missing fields required to proceed.\n",
            "\n",
            "Constraints:\n",
            "- Output in two lines only:\n",
            "  - 'intent: <one_of>[billing_issue|technical_issue|account_access|other]'\n",
            "  - 'missing_fields: [<comma-separated field names>]'\n",
            "\n",
            "User said: I was charged twice on my last invoice.\n",
            "\n",
            "Classify the user's issue and list missing fields. \n",
            "\n",
            "[CHAIN STEP] Classification raw response:\n",
            " intent: billing_issue\n",
            "missing_fields: ['account_id'] \n",
            "\n",
            "\n",
            "[CHAIN STEP] Request-info prompt:\n",
            " You are a support agent. Ask only ONE question that will help resolve the issue.\n",
            "Be polite, brief, and ask for exactly this field: account_id.\n",
            "Return only the question, no extra text. \n",
            "\n",
            "[CHAIN STEP] Request-info response:\n",
            " Sure—what is your 8-digit account ID? \n",
            "\n",
            "Question: (SupportState(user_message='I was charged twice on my last invoice.', intent='billing_issue', missing_fields=['account_id'], collected={}, resolution_plan=None, tone='friendly, concise, empathetic'), 'Sure—what is your 8-digit account ID?')\n",
            "\n",
            "[CHAIN STEP] Resolution-plan prompt:\n",
            " You are an internal support playbook generator.\n",
            "\n",
            "Context:\n",
            "- Intent: billing_issue\n",
            "- Known fields: {\"account_id\": \"12345678\"}\n",
            "- Tone: friendly, concise, empathetic\n",
            "\n",
            "Task: Propose a resolution plan as numbered steps and set a tone label.\n",
            "\n",
            "Output format (YAML-like):\n",
            "resolution_steps:\n",
            "  1) <step>\n",
            "  2) <step>\n",
            "tone: <one_or_two_words> \n",
            "\n",
            "[CHAIN STEP] Resolution-plan response:\n",
            " resolution_steps:\n",
            "1) Verify account_id in CRM\n",
            "2) Check last invoice and applied discounts\n",
            "3) Issue partial refund if overcharge confirmed\n",
            "tone: empathetic \n",
            "\n",
            "\n",
            "Final message:\n",
            " This is a mock response. Replace call_llm() to get real outputs.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "import re\n",
        "import json\n",
        "\n",
        "# --- Toggle this to False and implement your provider call in call_llm() ---\n",
        "SIMULATION = True\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Core LLM adapter (replace this stub with your real model call if desired)\n",
        "# ---------------------------------------------------------------------------\n",
        "def call_llm(prompt: str, system: Optional[str] = None, temperature: float = 0.2) -> str:\n",
        "    \"\"\"\n",
        "    Replace this with your real LLM SDK call. Keep the return as a plain string.\n",
        "    For practice, we simulate a response so the rest of the script runs offline.\n",
        "    \"\"\"\n",
        "    if SIMULATION:\n",
        "        # Lightweight mock behavior: produce short, plausible-looking text.\n",
        "        if \"Classify the user's issue\" in prompt:\n",
        "            return \"intent: billing_issue\\nmissing_fields: ['account_id']\"\n",
        "        if \"Ask only ONE question\" in prompt:\n",
        "            return \"Sure—what is your 8-digit account ID?\"\n",
        "        if \"Propose a resolution\" in prompt:\n",
        "            return (\"resolution_steps:\\n\"\n",
        "                    \"1) Verify account_id in CRM\\n\"\n",
        "                    \"2) Check last invoice and applied discounts\\n\"\n",
        "                    \"3) Issue partial refund if overcharge confirmed\\n\"\n",
        "                    \"tone: empathetic\")\n",
        "        if \"Draft the final message\" in prompt:\n",
        "            return (\"Hi there—thanks for reaching out. I can help with billing.\\n\"\n",
        "                    \"Could you share your 8-digit account ID so I can look into the recent charge?\\n\"\n",
        "                    \"Once I have it, I’ll verify your last invoice and correct any overcharge.\")\n",
        "        if \"ReACT-Style Code Task\" in prompt:\n",
        "            return (\n",
        "                \"Plan:\\n\"\n",
        "                \"- Normalize string: lowercase, remove non-alphanumerics.\\n\"\n",
        "                \"- Compare to its reverse.\\n\"\n",
        "                \"Final Code:\\n\"\n",
        "                \"```python\\n\"\n",
        "                \"import re\\n\"\n",
        "                \"def is_palindrome(s: str) -> bool:\\n\"\n",
        "                \"    cleaned = re.sub(r'[^0-9a-zA-Z]', '', s).lower()\\n\"\n",
        "                \"    return cleaned == cleaned[::-1]\\n\"\n",
        "                \"\\n\"\n",
        "                \"def _tests():\\n\"\n",
        "                \"    cases = [\\n\"\n",
        "                \"        (\\\"Madam, I'm Adam\\\", True),\\n\"\n",
        "                \"        (\\\"A man, a plan, a canal: Panama!\\\", True),\\n\"\n",
        "                \"        (\\\"palindrome\\\", False),\\n\"\n",
        "                \"        (\\\"No lemon, no melon\\\", True),\\n\"\n",
        "                \"    ]\\n\"\n",
        "                \"    for text, want in cases:\\n\"\n",
        "                \"        got = is_palindrome(text)\\n\"\n",
        "                \"        print(f'{text!r} -> {got} (want {want})')\\n\"\n",
        "                \"        assert got == want\\n\"\n",
        "                \"    return 'All tests passed.'\\n\"\n",
        "                \"\\n\"\n",
        "                \"if __name__ == '__main__':\\n\"\n",
        "                \"    print(_tests())\\n\"\n",
        "                \"```\\n\"\n",
        "            )\n",
        "        if \"Critique the summary\" in prompt:\n",
        "            return (\"Critique:\\n\"\n",
        "                    \"- Strengths: Clear, concise, captures main benefits.\\n\"\n",
        "                    \"- Gaps: No concrete metrics or examples; tone could be more customer-oriented.\\n\"\n",
        "                    \"- Improvements: Add a specific example and a brief call-to-action.\\n\")\n",
        "        if \"Rewrite an improved summary\" in prompt:\n",
        "            return (\"Improved Summary:\\n\"\n",
        "                    \"Our new onboarding cuts setup from days to hours, guiding teams step-by-step and reducing errors.\\n\"\n",
        "                    \"For example, Acme Co. activated 120 users in one afternoon with <2% support tickets.\\n\"\n",
        "                    \"Start with the checklist, invite your team, and track progress from the dashboard.\\n\")\n",
        "        # Default mock\n",
        "        return \"This is a mock response. Replace call_llm() to get real outputs.\"\n",
        "    else:\n",
        "        # Example (pseudocode) for real provider call; replace with your SDK:\n",
        "        # from openai import OpenAI\n",
        "        # client = OpenAI()\n",
        "        # rsp = client.chat.completions.create(\n",
        "        #     model=\"gpt-4o-mini\",\n",
        "        #     messages=[\n",
        "        #         {\"role\": \"system\", \"content\": system or \"You are a helpful assistant.\"},\n",
        "        #         {\"role\": \"user\", \"content\": prompt},\n",
        "        #     ],\n",
        "        #     temperature=temperature,\n",
        "        # )\n",
        "        # return rsp.choices[0].message.content\n",
        "        raise NotImplementedError(\"Implement your provider call here, or run in SIMULATION mode.\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1) Prompt Chaining for a Customer Support AI\n",
        "# ---------------------------------------------------------------------------\n",
        "@dataclass\n",
        "class SupportState:\n",
        "    user_message: str\n",
        "    intent: Optional[str] = None\n",
        "    missing_fields: List[str] = field(default_factory=list)\n",
        "    collected: Dict[str, Any] = field(default_factory=dict)\n",
        "    resolution_plan: Optional[str] = None\n",
        "    tone: str = \"friendly, concise, empathetic\"\n",
        "\n",
        "\n",
        "def chain_classify_issue(state: SupportState) -> SupportState:\n",
        "    prompt = f\"\"\"\n",
        "You are a customer support triage assistant.\n",
        "\n",
        "Task: Classify the user's issue and list any missing fields required to proceed.\n",
        "\n",
        "Constraints:\n",
        "- Output in two lines only:\n",
        "  - 'intent: <one_of>[billing_issue|technical_issue|account_access|other]'\n",
        "  - 'missing_fields: [<comma-separated field names>]'\n",
        "\n",
        "User said: {state.user_message}\n",
        "\n",
        "Classify the user's issue and list missing fields.\n",
        "\"\"\"\n",
        "    print(\"\\n[CHAIN STEP] Classification prompt:\\n\", prompt.strip(), \"\\n\")\n",
        "    raw = call_llm(prompt)\n",
        "    print(\"[CHAIN STEP] Classification raw response:\\n\", raw, \"\\n\")\n",
        "\n",
        "    # Parse simple mock format\n",
        "    intent_match = re.search(r\"intent:\\s*([a-z_]+)\", raw)\n",
        "    state.intent = intent_match.group(1) if intent_match else \"other\"\n",
        "\n",
        "    missing_match = re.search(r\"missing_fields:\\s*\\[(.*?)\\]\", raw, re.S)\n",
        "    if missing_match:\n",
        "        fields = [f.strip(\" '\\\"\\n\") for f in missing_match.group(1).split(\",\") if f.strip()]\n",
        "        state.missing_fields = fields\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def chain_request_info(state: SupportState) -> Tuple[SupportState, str]:\n",
        "    need = [f for f in state.missing_fields if f not in state.collected]\n",
        "    if not need:\n",
        "        return state, \"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a support agent. Ask only ONE question that will help resolve the issue.\n",
        "Be polite, brief, and ask for exactly this field: {need[0]}.\n",
        "Return only the question, no extra text.\n",
        "\"\"\"\n",
        "    print(\"\\n[CHAIN STEP] Request-info prompt:\\n\", prompt.strip(), \"\\n\")\n",
        "    question = call_llm(prompt)\n",
        "    print(\"[CHAIN STEP] Request-info response:\\n\", question, \"\\n\")\n",
        "    return state, question.strip()\n",
        "\n",
        "\n",
        "def chain_propose_resolution(state: SupportState) -> SupportState:\n",
        "    prompt = f\"\"\"\n",
        "You are an internal support playbook generator.\n",
        "\n",
        "Context:\n",
        "- Intent: {state.intent}\n",
        "- Known fields: {json.dumps(state.collected)}\n",
        "- Tone: {state.tone}\n",
        "\n",
        "Task: Propose a resolution plan as numbered steps and set a tone label.\n",
        "\n",
        "Output format (YAML-like):\n",
        "resolution_steps:\n",
        "  1) <step>\n",
        "  2) <step>\n",
        "tone: <one_or_two_words>\n",
        "\"\"\"\n",
        "    print(\"\\n[CHAIN STEP] Resolution-plan prompt:\\n\", prompt.strip(), \"\\n\")\n",
        "    raw = call_llm(prompt)\n",
        "    print(\"[CHAIN STEP] Resolution-plan response:\\n\", raw, \"\\n\")\n",
        "    state.resolution_plan = raw\n",
        "    # Try to extract a tone hint\n",
        "    m = re.search(r\"tone:\\s*([a-zA-Z _-]+)\", raw)\n",
        "    if m:\n",
        "        state.tone = m.group(1).strip()\n",
        "    return state\n",
        "\n",
        "\n",
        "def chain_draft_final_message(state: SupportState) -> str:\n",
        "    prompt = f\"\"\"\n",
        "You are a frontline customer support agent.\n",
        "\n",
        "Write the final reply to the user using this information:\n",
        "\n",
        "- User message: {state.user_message}\n",
        "- Intent: {state.intent}\n",
        "- Collected fields: {json.dumps(state.collected)}\n",
        "- Resolution plan:\\n{state.resolution_plan}\n",
        "\n",
        "Requirements:\n",
        "- Keep it under 120 words.\n",
        "- Use the tone: {state.tone}.\n",
        "- If information is still missing (e.g., account_id), politely request it first.\n",
        "- Be specific about next steps.\n",
        "\"\"\"\n",
        "    print(\"\\n[CHAIN STEP] Final-message prompt:\\n\", prompt.strip(), \"\\n\")\n",
        "    msg = call_llm(prompt, temperature=0.4)\n",
        "    print(\"[CHAIN STEP] Final-message response:\\n\", msg, \"\\n\")\n",
        "    return msg.strip()\n",
        "\n",
        "\n",
        "def run_support_chain(example_user_message: str, collected: Optional[Dict[str, Any]] = None) -> str:\n",
        "    state = SupportState(user_message=example_user_message, collected=collected or {})\n",
        "    state = chain_classify_issue(state)\n",
        "    state, question = chain_request_info(state)\n",
        "    if question and not state.collected.get(state.missing_fields[0]):\n",
        "        print(\"[ACTION NEEDED] Ask the user:\", question)\n",
        "        # In a real app, you'd wait for the user's answer here.\n",
        "        # For demo, we pretend the user provided an id:\n",
        "        state.collected[state.missing_fields[0]] = \"12345678\"\n",
        "\n",
        "    state = chain_propose_resolution(state)\n",
        "    return chain_draft_final_message(state)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    }
  ]
}