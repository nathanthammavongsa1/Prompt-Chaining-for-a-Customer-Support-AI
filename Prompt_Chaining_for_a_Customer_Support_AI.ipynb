{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7vZMJ2Wyt7i",
        "outputId": "b8643b22-9fdd-4dbf-ce39-c5ba136014aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "1) Prompt Chaining: Customer Support AI\n",
            "================================================================================\n",
            "\n",
            "[CHAIN STEP] Classification prompt:\n",
            " You are a customer support triage assistant.\n",
            "\n",
            "Task: Classify the user's issue and list any missing fields required to proceed.\n",
            "\n",
            "Constraints:\n",
            "- Output in two lines only:\n",
            "  - 'intent: <one_of>[billing_issue|technical_issue|account_access|other]'\n",
            "  - 'missing_fields: [<comma-separated field names>]'\n",
            "\n",
            "User said: I was charged twice on my last invoice and need a refund ASAP.\n",
            "\n",
            "Classify the user's issue and list missing fields. \n",
            "\n",
            "[CHAIN STEP] Classification raw response:\n",
            " intent: billing_issue\n",
            "missing_fields: ['account_id'] \n",
            "\n",
            "\n",
            "[CHAIN STEP] Request-info prompt:\n",
            " You are a support agent. Ask only ONE question that will help resolve the issue.\n",
            "Be polite, brief, and ask for exactly this field: account_id.\n",
            "Return only the question, no extra text. \n",
            "\n",
            "[CHAIN STEP] Request-info response:\n",
            " Sure—what is your 8-digit account ID? \n",
            "\n",
            "[ACTION NEEDED] Ask the user: Sure—what is your 8-digit account ID?\n",
            "\n",
            "[CHAIN STEP] Resolution-plan prompt:\n",
            " You are an internal support playbook generator.\n",
            "\n",
            "Context:\n",
            "- Intent: billing_issue\n",
            "- Known fields: {\"account_id\": \"12345678\"}\n",
            "- Tone: friendly, concise, empathetic\n",
            "\n",
            "Task: Propose a resolution plan as numbered steps and set a tone label.\n",
            "\n",
            "Output format (YAML-like):\n",
            "resolution_steps:\n",
            "  1) <step>\n",
            "  2) <step>\n",
            "tone: <one_or_two_words> \n",
            "\n",
            "[CHAIN STEP] Resolution-plan response:\n",
            " resolution_steps:\n",
            "1) Verify account_id in CRM\n",
            "2) Check last invoice and applied discounts\n",
            "3) Issue partial refund if overcharge confirmed\n",
            "tone: empathetic \n",
            "\n",
            "\n",
            "[CHAIN STEP] Final-message prompt:\n",
            " You are a frontline customer support agent.\n",
            "\n",
            "Write the final reply to the user using this information:\n",
            "\n",
            "- User message: I was charged twice on my last invoice and need a refund ASAP.\n",
            "- Intent: billing_issue\n",
            "- Collected fields: {\"account_id\": \"12345678\"}\n",
            "- Resolution plan:\n",
            "resolution_steps:\n",
            "1) Verify account_id in CRM\n",
            "2) Check last invoice and applied discounts\n",
            "3) Issue partial refund if overcharge confirmed\n",
            "tone: empathetic\n",
            "\n",
            "Requirements:\n",
            "- Keep it under 120 words.\n",
            "- Use the tone: empathetic.\n",
            "- If information is still missing (e.g., account_id), politely request it first.\n",
            "- Be specific about next steps. \n",
            "\n",
            "[CHAIN STEP] Final-message response:\n",
            " This is a mock response. Replace call_llm() to get real outputs. \n",
            "\n",
            "\n",
            "[FINAL SUPPORT MESSAGE]\n",
            " This is a mock response. Replace call_llm() to get real outputs.\n",
            "\n",
            "================================================================================\n",
            "2) ReACT-Style Code Generation\n",
            "================================================================================\n",
            "\n",
            "[REACT] Prompt sent to model:\n",
            " You are a careful coding assistant.\n",
            "\n",
            "ReACT-Style Code Task\n",
            "- Provide a **brief high-level plan** (3-5 bullets) under a heading \"Plan:\"\n",
            "- Then output **only the final Python code** inside a fenced block like:\n",
            "```python\n",
            "# code here\n",
            "```\n",
            "\n",
            "Task:\n",
            "Write a function is_palindrome(s) that returns True if s is a palindrome ignoring punctuation and case. Include 3-4 tests and print results.\n",
            "\n",
            "Constraints:\n",
            "- Prefer standard library only.\n",
            "- Include a small self-test that prints results when run as __main__.\n",
            "- Keep the plan high-level (no internal chain-of-thought), then produce final code. \n",
            "\n",
            "[REACT] Raw model response:\n",
            " Plan:\n",
            "- Normalize string: lowercase, remove non-alphanumerics.\n",
            "- Compare to its reverse.\n",
            "Final Code:\n",
            "```python\n",
            "import re\n",
            "def is_palindrome(s: str) -> bool:\n",
            "    cleaned = re.sub(r'[^0-9a-zA-Z]', '', s).lower()\n",
            "    return cleaned == cleaned[::-1]\n",
            "\n",
            "def _tests():\n",
            "    cases = [\n",
            "        (\"Madam, I'm Adam\", True),\n",
            "        (\"A man, a plan, a canal: Panama!\", True),\n",
            "        (\"palindrome\", False),\n",
            "        (\"No lemon, no melon\", True),\n",
            "    ]\n",
            "    for text, want in cases:\n",
            "        got = is_palindrome(text)\n",
            "        print(f'{text!r} -> {got} (want {want})')\n",
            "        assert got == want\n",
            "    return 'All tests passed.'\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    print(_tests())\n",
            "```\n",
            " \n",
            "\n",
            "[MODEL PLAN + CODE]\n",
            " Plan:\n",
            "- Normalize string: lowercase, remove non-alphanumerics.\n",
            "- Compare to its reverse.\n",
            "Final Code:\n",
            "```python\n",
            "import re\n",
            "def is_palindrome(s: str) -> bool:\n",
            "    cleaned = re.sub(r'[^0-9a-zA-Z]', '', s).lower()\n",
            "    return cleaned == cleaned[::-1]\n",
            "\n",
            "def _tests():\n",
            "    cases = [\n",
            "        (\"Madam, I'm Adam\", True),\n",
            "        (\"A man, a plan, a canal: Panama!\", True),\n",
            "        (\"palindrome\", False),\n",
            "        (\"No lemon, no melon\", True),\n",
            "    ]\n",
            "    for text, want in cases:\n",
            "        got = is_palindrome(text)\n",
            "        print(f'{text!r} -> {got} (want {want})')\n",
            "        assert got == want\n",
            "    return 'All tests passed.'\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    print(_tests())\n",
            "```\n",
            "\n",
            "\n",
            "[EXTRACTED CODE]\n",
            " import re\n",
            "def is_palindrome(s: str) -> bool:\n",
            "    cleaned = re.sub(r'[^0-9a-zA-Z]', '', s).lower()\n",
            "    return cleaned == cleaned[::-1]\n",
            "\n",
            "def _tests():\n",
            "    cases = [\n",
            "        (\"Madam, I'm Adam\", True),\n",
            "        (\"A man, a plan, a canal: Panama!\", True),\n",
            "        (\"palindrome\", False),\n",
            "        (\"No lemon, no melon\", True),\n",
            "    ]\n",
            "    for text, want in cases:\n",
            "        got = is_palindrome(text)\n",
            "        print(f'{text!r} -> {got} (want {want})')\n",
            "        assert got == want\n",
            "    return 'All tests passed.'\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    print(_tests())\n",
            "\n",
            "[CODE EXECUTION OUTPUT]\n",
            " Execution error: ImportError('__import__ not found')\n",
            "\n",
            "\n",
            "================================================================================\n",
            "3) Self-Reflection: Critique & Improve a Summary\n",
            "================================================================================\n",
            "\n",
            "[REFLECT] Initial summary prompt:\n",
            " Summarize the following text in 3-4 sentences for a general audience.\n",
            "Avoid marketing fluff; be clear and concrete.\n",
            "\n",
            "Text:\n",
            "We launched a new onboarding that replaces manual email back-and-forth with an in-app checklist, SSO setup guides, and role-based templates. Admins can invite users, assign roles, and track progress from a dashboard. Early cohorts reported fewer errors and a faster time-to-value. \n",
            "\n",
            "[REFLECT] Critique prompt:\n",
            " Critique the summary below. List 3-5 bullets for strengths and 3-5 bullets for improvements.\n",
            "Keep feedback concise and actionable.\n",
            "\n",
            "Summary to critique:\n",
            "This is a mock response. Replace call_llm() to get real outputs.\n",
            "\n",
            "Critique the summary. \n",
            "\n",
            "[REFLECT] Improve prompt:\n",
            " Using the critique below, rewrite an improved 3-4 sentence summary.\n",
            "Make it specific, concrete, and reader-focused.\n",
            "\n",
            "Critique:\n",
            "Critique:\n",
            "- Strengths: Clear, concise, captures main benefits.\n",
            "- Gaps: No concrete metrics or examples; tone could be more customer-oriented.\n",
            "- Improvements: Add a specific example and a brief call-to-action.\n",
            "\n",
            "\n",
            "Rewrite an improved summary. \n",
            "\n",
            "\n",
            "[INITIAL SUMMARY]\n",
            " This is a mock response. Replace call_llm() to get real outputs.\n",
            "\n",
            "[CRITIQUE]\n",
            " Critique:\n",
            "- Strengths: Clear, concise, captures main benefits.\n",
            "- Gaps: No concrete metrics or examples; tone could be more customer-oriented.\n",
            "- Improvements: Add a specific example and a brief call-to-action.\n",
            "\n",
            "[IMPROVED SUMMARY]\n",
            " Improved Summary:\n",
            "Our new onboarding cuts setup from days to hours, guiding teams step-by-step and reducing errors.\n",
            "For example, Acme Co. activated 120 users in one afternoon with <2% support tickets.\n",
            "Start with the checklist, invite your team, and track progress from the dashboard.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Prompt Engineering Practice in Python\n",
        "-------------------------------------\n",
        "This single script gives you three hands-on exercises:\n",
        "\n",
        "1) Prompt Chaining for a Customer Support AI\n",
        "2) Code Generation with a light-weight ReACT-style prompt (plan → code → run)\n",
        "3) Self-Reflection prompt to critique and improve an AI-written summary\n",
        "\n",
        "How to use:\n",
        "- By default the script runs in SIMULATION mode (no API calls). It will print the prompts that\n",
        "  would be sent to an LLM, and then produce simple mock outputs so you can see the flow.\n",
        "- If you want real model calls, replace `call_llm()` with your provider’s SDK call.\n",
        "  (e.g., OpenAI, Azure OpenAI, Anthropic, etc.).\n",
        "\n",
        "Run:\n",
        "    python prompt_engineering_practice.py\n",
        "\"\"\"\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "import re\n",
        "import json\n",
        "\n",
        "# --- Toggle this to False and implement your provider call in call_llm() ---\n",
        "SIMULATION = True\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Core LLM adapter (replace this stub with your real model call if desired)\n",
        "# ---------------------------------------------------------------------------\n",
        "def call_llm(prompt: str, system: Optional[str] = None, temperature: float = 0.2) -> str:\n",
        "    \"\"\"\n",
        "    Replace this with your real LLM SDK call. Keep the return as a plain string.\n",
        "    For practice, we simulate a response so the rest of the script runs offline.\n",
        "    \"\"\"\n",
        "    if SIMULATION:\n",
        "        # Lightweight mock behavior: produce short, plausible-looking text.\n",
        "        if \"Classify the user's issue\" in prompt:\n",
        "            return \"intent: billing_issue\\nmissing_fields: ['account_id']\"\n",
        "        if \"Ask only ONE question\" in prompt:\n",
        "            return \"Sure—what is your 8-digit account ID?\"\n",
        "        if \"Propose a resolution\" in prompt:\n",
        "            return (\"resolution_steps:\\n\"\n",
        "                    \"1) Verify account_id in CRM\\n\"\n",
        "                    \"2) Check last invoice and applied discounts\\n\"\n",
        "                    \"3) Issue partial refund if overcharge confirmed\\n\"\n",
        "                    \"tone: empathetic\")\n",
        "        if \"Draft the final message\" in prompt:\n",
        "            return (\"Hi there—thanks for reaching out. I can help with billing.\\n\"\n",
        "                    \"Could you share your 8-digit account ID so I can look into the recent charge?\\n\"\n",
        "                    \"Once I have it, I’ll verify your last invoice and correct any overcharge.\")\n",
        "        if \"ReACT-Style Code Task\" in prompt:\n",
        "            return (\n",
        "                \"Plan:\\n\"\n",
        "                \"- Normalize string: lowercase, remove non-alphanumerics.\\n\"\n",
        "                \"- Compare to its reverse.\\n\"\n",
        "                \"Final Code:\\n\"\n",
        "                \"```python\\n\"\n",
        "                \"import re\\n\"\n",
        "                \"def is_palindrome(s: str) -> bool:\\n\"\n",
        "                \"    cleaned = re.sub(r'[^0-9a-zA-Z]', '', s).lower()\\n\"\n",
        "                \"    return cleaned == cleaned[::-1]\\n\"\n",
        "                \"\\n\"\n",
        "                \"def _tests():\\n\"\n",
        "                \"    cases = [\\n\"\n",
        "                \"        (\\\"Madam, I'm Adam\\\", True),\\n\"\n",
        "                \"        (\\\"A man, a plan, a canal: Panama!\\\", True),\\n\"\n",
        "                \"        (\\\"palindrome\\\", False),\\n\"\n",
        "                \"        (\\\"No lemon, no melon\\\", True),\\n\"\n",
        "                \"    ]\\n\"\n",
        "                \"    for text, want in cases:\\n\"\n",
        "                \"        got = is_palindrome(text)\\n\"\n",
        "                \"        print(f'{text!r} -> {got} (want {want})')\\n\"\n",
        "                \"        assert got == want\\n\"\n",
        "                \"    return 'All tests passed.'\\n\"\n",
        "                \"\\n\"\n",
        "                \"if __name__ == '__main__':\\n\"\n",
        "                \"    print(_tests())\\n\"\n",
        "                \"```\\n\"\n",
        "            )\n",
        "        if \"Critique the summary\" in prompt:\n",
        "            return (\"Critique:\\n\"\n",
        "                    \"- Strengths: Clear, concise, captures main benefits.\\n\"\n",
        "                    \"- Gaps: No concrete metrics or examples; tone could be more customer-oriented.\\n\"\n",
        "                    \"- Improvements: Add a specific example and a brief call-to-action.\\n\")\n",
        "        if \"Rewrite an improved summary\" in prompt:\n",
        "            return (\"Improved Summary:\\n\"\n",
        "                    \"Our new onboarding cuts setup from days to hours, guiding teams step-by-step and reducing errors.\\n\"\n",
        "                    \"For example, Acme Co. activated 120 users in one afternoon with <2% support tickets.\\n\"\n",
        "                    \"Start with the checklist, invite your team, and track progress from the dashboard.\\n\")\n",
        "        # Default mock\n",
        "        return \"This is a mock response. Replace call_llm() to get real outputs.\"\n",
        "    else:\n",
        "        # Example (pseudocode) for real provider call; replace with your SDK:\n",
        "        # from openai import OpenAI\n",
        "        # client = OpenAI()\n",
        "        # rsp = client.chat.completions.create(\n",
        "        #     model=\"gpt-4o-mini\",\n",
        "        #     messages=[\n",
        "        #         {\"role\": \"system\", \"content\": system or \"You are a helpful assistant.\"},\n",
        "        #         {\"role\": \"user\", \"content\": prompt},\n",
        "        #     ],\n",
        "        #     temperature=temperature,\n",
        "        # )\n",
        "        # return rsp.choices[0].message.content\n",
        "        raise NotImplementedError(\"Implement your provider call here, or run in SIMULATION mode.\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1) Prompt Chaining for a Customer Support AI\n",
        "# ---------------------------------------------------------------------------\n",
        "@dataclass\n",
        "class SupportState:\n",
        "    user_message: str\n",
        "    intent: Optional[str] = None\n",
        "    missing_fields: List[str] = field(default_factory=list)\n",
        "    collected: Dict[str, Any] = field(default_factory=dict)\n",
        "    resolution_plan: Optional[str] = None\n",
        "    tone: str = \"friendly, concise, empathetic\"\n",
        "\n",
        "\n",
        "def chain_classify_issue(state: SupportState) -> SupportState:\n",
        "    prompt = f\"\"\"\n",
        "You are a customer support triage assistant.\n",
        "\n",
        "Task: Classify the user's issue and list any missing fields required to proceed.\n",
        "\n",
        "Constraints:\n",
        "- Output in two lines only:\n",
        "  - 'intent: <one_of>[billing_issue|technical_issue|account_access|other]'\n",
        "  - 'missing_fields: [<comma-separated field names>]'\n",
        "\n",
        "User said: {state.user_message}\n",
        "\n",
        "Classify the user's issue and list missing fields.\n",
        "\"\"\"\n",
        "    print(\"\\n[CHAIN STEP] Classification prompt:\\n\", prompt.strip(), \"\\n\")\n",
        "    raw = call_llm(prompt)\n",
        "    print(\"[CHAIN STEP] Classification raw response:\\n\", raw, \"\\n\")\n",
        "\n",
        "    # Parse simple mock format\n",
        "    intent_match = re.search(r\"intent:\\s*([a-z_]+)\", raw)\n",
        "    state.intent = intent_match.group(1) if intent_match else \"other\"\n",
        "\n",
        "    missing_match = re.search(r\"missing_fields:\\s*\\[(.*?)\\]\", raw, re.S)\n",
        "    if missing_match:\n",
        "        fields = [f.strip(\" '\\\"\\n\") for f in missing_match.group(1).split(\",\") if f.strip()]\n",
        "        state.missing_fields = fields\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def chain_request_info(state: SupportState) -> Tuple[SupportState, str]:\n",
        "    need = [f for f in state.missing_fields if f not in state.collected]\n",
        "    if not need:\n",
        "        return state, \"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a support agent. Ask only ONE question that will help resolve the issue.\n",
        "Be polite, brief, and ask for exactly this field: {need[0]}.\n",
        "Return only the question, no extra text.\n",
        "\"\"\"\n",
        "    print(\"\\n[CHAIN STEP] Request-info prompt:\\n\", prompt.strip(), \"\\n\")\n",
        "    question = call_llm(prompt)\n",
        "    print(\"[CHAIN STEP] Request-info response:\\n\", question, \"\\n\")\n",
        "    return state, question.strip()\n",
        "\n",
        "\n",
        "def chain_propose_resolution(state: SupportState) -> SupportState:\n",
        "    prompt = f\"\"\"\n",
        "You are an internal support playbook generator.\n",
        "\n",
        "Context:\n",
        "- Intent: {state.intent}\n",
        "- Known fields: {json.dumps(state.collected)}\n",
        "- Tone: {state.tone}\n",
        "\n",
        "Task: Propose a resolution plan as numbered steps and set a tone label.\n",
        "\n",
        "Output format (YAML-like):\n",
        "resolution_steps:\n",
        "  1) <step>\n",
        "  2) <step>\n",
        "tone: <one_or_two_words>\n",
        "\"\"\"\n",
        "    print(\"\\n[CHAIN STEP] Resolution-plan prompt:\\n\", prompt.strip(), \"\\n\")\n",
        "    raw = call_llm(prompt)\n",
        "    print(\"[CHAIN STEP] Resolution-plan response:\\n\", raw, \"\\n\")\n",
        "    state.resolution_plan = raw\n",
        "    # Try to extract a tone hint\n",
        "    m = re.search(r\"tone:\\s*([a-zA-Z _-]+)\", raw)\n",
        "    if m:\n",
        "        state.tone = m.group(1).strip()\n",
        "    return state\n",
        "\n",
        "\n",
        "def chain_draft_final_message(state: SupportState) -> str:\n",
        "    prompt = f\"\"\"\n",
        "You are a frontline customer support agent.\n",
        "\n",
        "Write the final reply to the user using this information:\n",
        "\n",
        "- User message: {state.user_message}\n",
        "- Intent: {state.intent}\n",
        "- Collected fields: {json.dumps(state.collected)}\n",
        "- Resolution plan:\\n{state.resolution_plan}\n",
        "\n",
        "Requirements:\n",
        "- Keep it under 120 words.\n",
        "- Use the tone: {state.tone}.\n",
        "- If information is still missing (e.g., account_id), politely request it first.\n",
        "- Be specific about next steps.\n",
        "\"\"\"\n",
        "    print(\"\\n[CHAIN STEP] Final-message prompt:\\n\", prompt.strip(), \"\\n\")\n",
        "    msg = call_llm(prompt, temperature=0.4)\n",
        "    print(\"[CHAIN STEP] Final-message response:\\n\", msg, \"\\n\")\n",
        "    return msg.strip()\n",
        "\n",
        "\n",
        "def run_support_chain(example_user_message: str, collected: Optional[Dict[str, Any]] = None) -> str:\n",
        "    state = SupportState(user_message=example_user_message, collected=collected or {})\n",
        "    state = chain_classify_issue(state)\n",
        "    state, question = chain_request_info(state)\n",
        "    if question and not state.collected.get(state.missing_fields[0]):\n",
        "        print(\"[ACTION NEEDED] Ask the user:\", question)\n",
        "        # In a real app, you'd wait for the user's answer here.\n",
        "        # For demo, we pretend the user provided an id:\n",
        "        state.collected[state.missing_fields[0]] = \"12345678\"\n",
        "\n",
        "    state = chain_propose_resolution(state)\n",
        "    return chain_draft_final_message(state)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}